# ensemble_final.py
"""
æœ€ç»ˆé›†æˆé£é™©è¯„ä¼°å¼•æ“
èåˆï¼š
1. ClimaHealth AI çš„ LSTM/Prophet æ°”å€™é¢„æµ‹
2. DL_climate çš„ç–¾ç—…ç‰¹å¼‚æ€§é£é™©é€»è¾‘
3. å¢å¼ºç‰ˆ NLP æ£€æµ‹å™¨
4. SHAP å¯è§£é‡Šæ€§ï¼ˆClimaHealth AIï¼‰
5. åŠ¨æ€æƒé‡è°ƒæ•´ï¼ˆæ–°å¢ï¼‰
"""

import numpy as np
import pandas as pd
from typing import Dict, List


class FinalRiskEngine:
    """
    èåˆé£é™©è¯„ä¼°å¼•æ“
    
    ç»„ä»¶æƒé‡ï¼š
    - Climate Forecast: 35%
    - Disease Model: 50%
    - NLP Signals: 15%
    
    æƒé‡æ ¹æ®æ•°æ®å¯ç”¨æ€§å’Œç–¾ç—…ç‰¹æ€§åŠ¨æ€è°ƒæ•´
    """
    
    def __init__(
        self,
        climate_forecaster,     # ClimaHealth AI çš„ ClimateForecaster
        disease_predictor,      # å¢å¼ºç‰ˆ EnhancedDiseasePredictor
        nlp_detector,          # å¢å¼ºç‰ˆ EnhancedOutbreakDetector
    ):
        self.climate_forecaster = climate_forecaster
        self.disease_predictor = disease_predictor
        self.nlp_detector = nlp_detector
        
        # åŸºç¡€æƒé‡ï¼ˆå¯æ ¹æ®æƒ…å†µè°ƒæ•´ï¼‰
        self.base_weights = {
            'climate': 0.35,
            'disease': 0.50,
            'nlp': 0.15
        }
    
    def assess_risk(
        self,
        region: str,
        disease: str,
        climate_df: pd.DataFrame,
        recent_cases: np.ndarray,
        news_texts: List[str],
        forecast_weeks: int = 8
    ) -> Dict:
        """
        ç»¼åˆé£é™©è¯„ä¼°
        
        å‚æ•°:
            region: åœ°åŒºåç§° (å¦‚ 'dhaka_bangladesh')
            disease: ç–¾ç—…ç±»å‹ ('malaria'/'dengue'/...)
            climate_df: å†å²æ°”å€™æ•°æ®ï¼ˆè‡³å°‘ 12 å‘¨ï¼‰
            recent_cases: è¿‘æœŸç—…ä¾‹æ•°ï¼ˆè‡³å°‘ 12 å‘¨ï¼‰
            news_texts: è¿‘æœŸæ–°é—»æ ‡é¢˜åˆ—è¡¨
            forecast_weeks: é¢„æµ‹æœªæ¥å‘¨æ•°
        
        è¿”å›:
            {
                'risk_score': float (0-100),
                'risk_level': str,
                'confidence': float,
                'component_scores': {...},
                'climate_forecast': [...],
                'nlp_signals': [...],
                'recommended_actions': [...],
                'shap_summary': {...},
                'uncertainty_bounds': {...}
            }
        """
        
        # =====================================
        # 1. æ°”å€™é¢„æµ‹ï¼ˆä½¿ç”¨ ClimaHealth AI çš„ LSTM+Prophetï¼‰
        # =====================================
        climate_forecast = self.climate_forecaster.forecast(
            climate_df, 
            weeks=forecast_weeks
        )
        climate_risk = self._calculate_climate_risk(
            climate_df.iloc[-1], 
            climate_forecast,
            disease
        )
        
        # =====================================
        # 2. ç–¾ç—…æ¨¡å‹é¢„æµ‹ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆé›†æˆæ¨¡å‹ï¼‰
        # =====================================
        # åº”ç”¨é¢†åŸŸç‰¹å¾å·¥ç¨‹
        from disease_domain_features import DomainFeatureManager
        feature_manager = DomainFeatureManager()
        enhanced_features = feature_manager.engineer_features(climate_df, disease)
        
        # æå–æœ€æ–°ç‰¹å¾å‘é‡
        latest_features = self._extract_latest_features(
            enhanced_features, 
            recent_cases,
            disease
        )
        
        # é¢„æµ‹
        _, disease_prob = self.disease_predictor.predict(latest_features.reshape(1, -1))
        disease_risk = disease_prob[0] * 100
        
        # =====================================
        # 3. NLP ä¿¡å·åˆ†æï¼ˆä½¿ç”¨å¢å¼ºç‰ˆæ£€æµ‹å™¨ï¼‰
        # =====================================
        nlp_results = self.nlp_detector.predict(news_texts)
        
        # ç­›é€‰ç›¸å…³ç–¾ç—…çš„çˆ†å‘ä¿¡å·
        relevant_signals = [
            r for r in nlp_results 
            if r['is_outbreak'] and r['disease'] == disease
        ]
        
        if relevant_signals:
            nlp_risk = np.mean([s['confidence'] for s in relevant_signals]) * 100
            nlp_urgency = np.max([s['urgency_score'] for s in relevant_signals])
        else:
            nlp_risk = 0
            nlp_urgency = 0
        
        # =====================================
        # 4. åŠ¨æ€æƒé‡è°ƒæ•´
        # =====================================
        adjusted_weights = self._adjust_weights(
            climate_data_quality=self._assess_data_quality(climate_df),
            nlp_signal_count=len(relevant_signals),
            disease=disease
        )
        
        # =====================================
        # 5. è®¡ç®—æœ€ç»ˆé£é™©åˆ†æ•°
        # =====================================
        final_score = (
            adjusted_weights['climate'] * climate_risk +
            adjusted_weights['disease'] * disease_risk +
            adjusted_weights['nlp'] * nlp_risk
        )
        
        # ç´§æ€¥ç¨‹åº¦åŠ æƒï¼ˆNLP é«˜ç´§æ€¥åº¦æ—¶æå‡æ€»åˆ†ï¼‰
        if nlp_urgency > 0.8:
            final_score = min(100, final_score * 1.15)
        
        # =====================================
        # 6. é£é™©ç­‰çº§åˆ’åˆ†
        # =====================================
        risk_level = self._categorize_risk(final_score, nlp_urgency)
        
        # =====================================
        # 7. ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆæ–°å¢ï¼‰
        # =====================================
        uncertainty = self._compute_uncertainty(
            climate_forecast,
            disease_prob[0],
            nlp_results
        )
        
        # =====================================
        # 8. SHAP ç‰¹å¾é‡è¦æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰
        # =====================================
        shap_summary = self._compute_shap_approximation(
            climate_risk,
            disease_risk,
            nlp_risk,
            adjusted_weights
        )
        
        # =====================================
        # 9. ç”Ÿæˆè¡ŒåŠ¨å»ºè®®
        # =====================================
        actions = self._generate_actions(
            risk_level, 
            disease,
            enhanced_features.iloc[-1],
            nlp_urgency
        )
        
        # =====================================
        # 10. è¿”å›å®Œæ•´è¯„ä¼°
        # =====================================
        return {
            'region': region,
            'disease': disease,
            'risk_score': round(final_score, 1),
            'risk_level': risk_level,
            'confidence': round(1 - uncertainty['total'], 2),
            'outbreak_probability': round(disease_prob[0], 3),
            
            'component_scores': {
                'climate_risk': round(climate_risk, 1),
                'disease_ensemble_risk': round(disease_risk, 1),
                'nlp_signal_risk': round(nlp_risk, 1),
            },
            
            'component_weights': adjusted_weights,
            
            'climate_forecast': climate_forecast,
            
            'nlp_signals': nlp_results,
            'nlp_urgency': round(nlp_urgency, 2),
            
            'recommended_actions': actions,
            
            'shap_summary': shap_summary,
            
            'uncertainty_bounds': {
                'lower': round(max(0, final_score - uncertainty['margin']), 1),
                'upper': round(min(100, final_score + uncertainty['margin']), 1),
                'sources': uncertainty
            }
        }
    
    def _calculate_climate_risk(
        self, 
        current_climate: pd.Series,
        forecast: List[Dict],
        disease: str
    ) -> float:
        """
        è®¡ç®—æ°”å€™é£é™©åˆ†æ•°
        èåˆ DL_climate çš„ç–¾ç—…ç‰¹å¼‚æ€§é€»è¾‘
        """
        from disease_domain_features import DomainFeatureManager
        
        manager = DomainFeatureManager()
        model = manager.disease_models[disease]
        optimal_range = model.get_optimal_climate_range()
        
        # å½“å‰æ°”å€™æ¡ä»¶è¯„åˆ†
        temp = current_climate['temperature']
        precip = current_climate.get('precipitation', 0)
        
        # æ¸©åº¦é£é™©
        temp_low, temp_high = optimal_range['temperature']
        if temp_low <= temp <= temp_high:
            temp_risk = 80 + (1 - abs(temp - np.mean([temp_low, temp_high])) / (temp_high - temp_low)) * 20
        elif abs(temp - temp_low) < 5 or abs(temp - temp_high) < 5:
            temp_risk = 60
        else:
            temp_risk = 30
        
        # é™æ°´é£é™©
        precip_low, precip_high = optimal_range['precipitation']
        if precip_low <= precip <= precip_high:
            precip_risk = 75
        elif precip > precip_high:
            precip_risk = 85  # è¿‡é‡é™æ°´é«˜é£é™©
        else:
            precip_risk = 40
        
        # é¢„æµ‹è¶‹åŠ¿è°ƒæ•´
        forecast_temps = [f['temperature'] for f in forecast]
        if np.mean(forecast_temps) > temp_high:
            trend_adjustment = 1.1  # è¶‹åŠ¿å‘é«˜é£é™©
        elif np.mean(forecast_temps) < temp_low:
            trend_adjustment = 0.9
        else:
            trend_adjustment = 1.0
        
        base_risk = (temp_risk + precip_risk) / 2
        return min(100, base_risk * trend_adjustment)
    
    def _extract_latest_features(
        self,
        enhanced_features: pd.DataFrame,
        recent_cases: np.ndarray,
        disease: str
    ) -> np.ndarray:
        """æå–æœ€æ–°çš„ç‰¹å¾å‘é‡"""
        # åŸºç¡€ç‰¹å¾
        latest = enhanced_features.iloc[-1]
        features = [
            latest['temperature'],
            latest['precipitation'],
            latest['humidity'],
        ]
        
        # æ»åç‰¹å¾
        for lag in [1, 2, 4]:
            features.append(latest.get(f'temp_lag_{lag}', latest['temperature']))
            features.append(latest.get(f'precip_lag_{lag}', latest['precipitation']))
        
        # æ»šåŠ¨ç»Ÿè®¡
        features.append(latest.get('temp_rolling_4w', latest['temperature']))
        features.append(latest.get('precip_rolling_4w', latest['precipitation']))
        
        # ç–¾ç—…ç‰¹å¼‚æ€§ç‰¹å¾
        features.append(latest.get(f'{disease}_transmission_factor', 1.0))
        features.append(latest.get(f'{disease}_temp_deviation', 0))
        features.append(latest.get(f'{disease}_precip_deviation', 0))
        features.append(latest.get(f'{disease}_high_risk', 0))
        
        return np.array(features)
    
    def _adjust_weights(
        self,
        climate_data_quality: float,
        nlp_signal_count: int,
        disease: str
    ) -> Dict[str, float]:
        """åŠ¨æ€è°ƒæ•´ç»„ä»¶æƒé‡"""
        weights = self.base_weights.copy()
        
        # 1. æ°”å€™æ•°æ®è´¨é‡ä½ â†’ é™ä½æ°”å€™æƒé‡ï¼Œæå‡ç–¾ç—…æ¨¡å‹æƒé‡
        if climate_data_quality < 0.7:
            weights['climate'] *= 0.8
            weights['disease'] += (self.base_weights['climate'] - weights['climate'])
        
        # 2. NLP ä¿¡å·å¼ºçƒˆ â†’ æå‡ NLP æƒé‡
        if nlp_signal_count >= 3:
            boost = 0.05
            weights['nlp'] += boost
            weights['climate'] -= boost * 0.5
            weights['disease'] -= boost * 0.5
        
        # 3. ç–¾ç—…ç‰¹æ€§è°ƒæ•´
        disease_adjustments = {
            'malaria': {'climate': 1.1, 'disease': 1.0, 'nlp': 0.9},  # æ°”å€™æ•æ„Ÿ
            'dengue': {'climate': 1.0, 'disease': 1.1, 'nlp': 1.0},   # ç–¾ç—…æ¨¡å‹é‡è¦
            'cholera': {'climate': 0.9, 'disease': 1.0, 'nlp': 1.2},  # çªå‘äº‹ä»¶æ•æ„Ÿ
            'zika': {'climate': 1.0, 'disease': 1.0, 'nlp': 1.1},
        }
        
        if disease in disease_adjustments:
            for key in weights:
                weights[key] *= disease_adjustments[disease][key]
        
        # å½’ä¸€åŒ–
        total = sum(weights.values())
        return {k: v/total for k, v in weights.items()}
    
    def _assess_data_quality(self, climate_df: pd.DataFrame) -> float:
        """è¯„ä¼°æ°”å€™æ•°æ®è´¨é‡"""
        missing_rate = climate_df.isnull().mean().mean()
        return 1 - missing_rate
    
    def _categorize_risk(self, score: float, nlp_urgency: float) -> str:
        """é£é™©ç­‰çº§åˆ†ç±»"""
        # é«˜ç´§æ€¥åº¦æ—¶é™ä½é˜ˆå€¼
        if nlp_urgency > 0.8:
            if score >= 65:
                return 'critical'
            elif score >= 50:
                return 'high'
            elif score >= 35:
                return 'medium'
            else:
                return 'low'
        else:
            if score >= 75:
                return 'critical'
            elif score >= 60:
                return 'high'
            elif score >= 40:
                return 'medium'
            else:
                return 'low'
    
    def _compute_uncertainty(
        self,
        climate_forecast: List[Dict],
        disease_prob: float,
        nlp_results: List[Dict]
    ) -> Dict:
        """ä¸ç¡®å®šæ€§é‡åŒ–"""
        # 1. æ°”å€™é¢„æµ‹ä¸ç¡®å®šæ€§ï¼ˆå‡è®¾æœ‰ç½®ä¿¡åŒºé—´ï¼‰
        climate_uncertainty = 0.15  # 15% åŸºç¡€ä¸ç¡®å®šæ€§
        
        # 2. ç–¾ç—…æ¨¡å‹ä¸ç¡®å®šæ€§ï¼ˆåŸºäºæ¦‚ç‡ï¼‰
        disease_uncertainty = abs(0.5 - disease_prob)  # è¶Šæ¥è¿‘ 0.5 è¶Šä¸ç¡®å®š
        
        # 3. NLP ä¸ç¡®å®šæ€§ï¼ˆåŸºäºä¿¡å·ä¸€è‡´æ€§ï¼‰
        if nlp_results:
            nlp_confidences = [r['confidence'] for r in nlp_results]
            nlp_uncertainty = 1 - np.mean(nlp_confidences)
        else:
            nlp_uncertainty = 0.5  # æ— ä¿¡å·æ—¶ä¸­ç­‰ä¸ç¡®å®šæ€§
        
        total_uncertainty = np.mean([
            climate_uncertainty,
            disease_uncertainty,
            nlp_uncertainty
        ])
        
        margin = total_uncertainty * 100  # è½¬æ¢ä¸ºåˆ†æ•°èŒƒå›´
        
        return {
            'climate': round(climate_uncertainty, 2),
            'disease': round(disease_uncertainty, 2),
            'nlp': round(nlp_uncertainty, 2),
            'total': round(total_uncertainty, 2),
            'margin': round(margin, 1)
        }
    
    def _compute_shap_approximation(
        self,
        climate_risk: float,
        disease_risk: float,
        nlp_risk: float,
        weights: Dict[str, float]
    ) -> Dict[str, float]:
        """SHAP ç‰¹å¾é‡è¦æ€§è¿‘ä¼¼"""
        contributions = {
            'climate_factors': climate_risk * weights['climate'] / 100,
            'disease_model': disease_risk * weights['disease'] / 100,
            'nlp_signals': nlp_risk * weights['nlp'] / 100,
        }
        
        # å½’ä¸€åŒ–ä¸ºæ¯”ä¾‹
        total = sum(contributions.values())
        if total > 0:
            return {k: v/total for k, v in contributions.items()}
        else:
            return {k: 1/3 for k in contributions.keys()}
    
    def _generate_actions(
        self,
        risk_level: str,
        disease: str,
        current_features: pd.Series,
        nlp_urgency: float
    ) -> List[str]:
        """
        ç”Ÿæˆè¡ŒåŠ¨å»ºè®®
        èåˆ DL_climate çš„åˆ†çº§å»ºè®®é€»è¾‘
        """
        actions = []
        
        # === Critical çº§åˆ« ===
        if risk_level == 'critical':
            actions.extend([
                f'ğŸš¨ ç«‹å³å¯åŠ¨{disease}ç´§æ€¥é˜²æ§å“åº”',
                'æ‰©å¤§å®¤å†…æ®‹ç•™å–·é›¾ï¼ˆIRSï¼‰è¦†ç›–èŒƒå›´' if disease in ['malaria', 'dengue'] else 'ç´§æ€¥æ¸…æ´æ°´æºç³»ç»Ÿ',
                f'åŠ å¼º{disease}å¿«é€Ÿè¯Šæ–­å’Œæ²»ç–—',
                'åˆ†å‘é•¿æ•ˆæ€è™«èšŠå¸ï¼ˆLLINsï¼‰' if disease in ['malaria', 'dengue', 'zika'] else 'åˆ†å‘å£æœè¡¥æ¶²ç›',
                'å¼€å±•å¤§è§„æ¨¡åª’ä»‹æ§åˆ¶æ´»åŠ¨',
                'åŠ å¼ºç–«æƒ…ç›‘æµ‹å’ŒæŠ¥å‘Šç³»ç»Ÿ',
            ])
            
            if nlp_urgency > 0.8:
                actions.append('ğŸ“¢ å¯åŠ¨å…¬ä¼—ç´§æ€¥è­¦æŠ¥ç³»ç»Ÿ')
        
        # === High çº§åˆ« ===
        elif risk_level == 'high':
            actions.extend([
                'åŠ å¼ºèšŠè™«æ»‹ç”Ÿåœ°æ¸…ç†' if disease in ['malaria', 'dengue', 'zika'] else 'ç›‘æµ‹æ°´æºæ±¡æŸ“',
                f'å¢åŠ {disease}ç­›æŸ¥é¢‘ç‡',
                'æå‡ç¤¾åŒºå¥åº·æ•™è‚²',
                f'ç¡®ä¿æŠ—{disease}è¯ç‰©åº“å­˜å……è¶³',
                'å‡†å¤‡åº”æ€¥å“åº”èµ„æº',
            ])
        
        # === Medium çº§åˆ« ===
        elif risk_level == 'medium':
            actions.extend([
                f'ç»´æŒå¸¸è§„{disease}ç›‘æµ‹',
                'ç»§ç»­èšŠå¸ä½¿ç”¨å®£ä¼ ' if disease in ['malaria', 'dengue', 'zika'] else 'ç»´æŒå«ç”Ÿè®¾æ–½è¿è½¬',
                'ç›‘æ§æ°”å€™å˜åŒ–è¶‹åŠ¿',
                'åŠ å¼ºé«˜é£é™©äººç¾¤ä¿æŠ¤',
            ])
        
        # === Low çº§åˆ« ===
        else:
            actions.extend([
                'ç»§ç»­å¸¸è§„é¢„é˜²æªæ–½',
                'ä¿æŒç¤¾åŒºå«ç”Ÿæ„è¯†',
                'å®šæœŸæ£€æŸ¥é˜²æŠ¤è®¾æ–½å®Œæ•´æ€§',
            ])
        
        return actions


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

if __name__ == '__main__':
    # å‡è®¾å·²åŠ è½½æ¨¡å‹
    from models.climate_forecaster import ClimateForecaster
    from train_enhanced import EnhancedDiseasePredictor
    from nlp_detector_enhanced import EnhancedOutbreakDetector
    
    climate_model = ClimateForecaster.load('saved_models/climate_forecaster.pkl')
    malaria_model = EnhancedDiseasePredictor.load('saved_models/enhanced_malaria_predictor.pkl')
    nlp_model = EnhancedOutbreakDetector.load('saved_models/enhanced_nlp_detector.pkl')
    
    # åˆ›å»ºå¼•æ“
    engine = FinalRiskEngine(climate_model, malaria_model, nlp_model)
    
    # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    climate_data = pd.DataFrame({
        'temperature': [26, 27, 28, 27, 26, 25, 24, 25, 26, 27, 28, 29],
        'precipitation': [120, 150, 180, 200, 220, 180, 160, 140, 130, 150, 170, 190],
        'humidity': [75, 78, 80, 82, 85, 83, 80, 78, 76, 77, 79, 81],
    })
    
    recent_cases = np.array([45, 52, 60, 75, 90, 110, 95, 85, 80, 88, 95, 105])
    
    news = [
        'Malaria cases surge in rural districts following heavy monsoon rains',
        'WHO warns of severe malaria season ahead as temperatures rise',
        'Emergency malaria clinics set up in affected communities',
    ]
    
    # è¯„ä¼°é£é™©
    assessment = engine.assess_risk(
        region='sub_saharan_africa',
        disease='malaria',
        climate_df=climate_data,
        recent_cases=recent_cases,
        news_texts=news,
        forecast_weeks=8
    )
    
    # æ‰“å°ç»“æœ
    print('\n' + '='*70)
    print(f'  {assessment["disease"].upper()} é£é™©è¯„ä¼° - {assessment["region"]}')
    print('='*70)
    print(f"  é£é™©åˆ†æ•°:      {assessment['risk_score']}/100")
    print(f"  é£é™©ç­‰çº§:      {assessment['risk_level'].upper()}")
    print(f"  ç½®ä¿¡åº¦:        {assessment['confidence']*100:.1f}%")
    print(f"  çˆ†å‘æ¦‚ç‡:      {assessment['outbreak_probability']*100:.1f}%")
    
    print(f"\n  ç»„ä»¶åˆ†æ•°:")
    for comp, score in assessment['component_scores'].items():
        weight = assessment['component_weights'][comp.split('_')[0]]
        print(f"    {comp:30s} {score:>6.1f}/100 (æƒé‡: {weight*100:.1f}%)")
    
    print(f"\n  ä¸ç¡®å®šæ€§è¾¹ç•Œ: [{assessment['uncertainty_bounds']['lower']}, {assessment['uncertainty_bounds']['upper']}]")
    
    print(f"\n  æ¨èè¡ŒåŠ¨:")
    for i, action in enumerate(assessment['recommended_actions'], 1):
        print(f"    {i}. {action}")
    
    print('='*70)
