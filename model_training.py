# -*- coding: utf-8 -*-
"""MODI_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15WfAbpn-wpaqwwB-Mswhi2SOVfzpgrT8
"""

# Commented out IPython magic to ensure Python compatibility.
# ============================================
# ç¬¬ 1 æ­¥ï¼šç¯å¢ƒå‡†å¤‡
# ============================================
print("="*70)
print("  ğŸš€ ClimaHealth AI")
print("="*70)

# ä¸Šä¼ é¡¹ç›®å‹ç¼©åŒ…
from google.colab import files
print("\n climahealth-ai.zip æ–‡ä»¶")
uploaded = files.upload()

# è§£å‹
!unzip -q climahealth-ai.zip
# %cd climahealth-ai/backend

# å®‰è£…ä¾èµ–
!pip install -q requests pandas scikit-learn joblib matplotlib seaborn

print("\âœ…")

# ============================================
# ç¬¬ 2 æ­¥ï¼šåˆ›å»ºèåˆæ¨¡å—æ–‡ä»¶ - Part 1
# ============================================
print("\n" + "="*70)
print("  ğŸ“ åˆ›å»ºç–¾ç—…é¢†åŸŸç‰¹å¾å·¥ç¨‹æ¨¡å—")
print("="*70)

disease_features_code = "disease_domain_features.py"
"""
èåˆ DL_climate çš„é¢†åŸŸå»ºæ¨¡ + ClimaHealth AI çš„é€šç”¨æ¡†æ¶
ä¸ºæ¯ç§ç–¾ç—…å®šåˆ¶ç‰¹å¾å·¥ç¨‹ï¼ŒåŸºäºæµè¡Œç—…å­¦åŸç†
"""

import numpy as np
import pandas as pd
from abc import ABC, abstractmethod

class DiseaseFeatureEngineer(ABC):
    """ç–¾ç—…ç‰¹å¾å·¥ç¨‹åŸºç±»"""

    @abstractmethod
    def compute_transmission_factor(self, climate_df: pd.DataFrame) -> np.ndarray:
        pass

    @abstractmethod
    def get_optimal_climate_range(self) -> dict:
        pass


class MalariaFeatures(DiseaseFeatureEngineer):
    """ç–Ÿç–¾ç‰¹å¼‚æ€§ç‰¹å¾ï¼ˆèåˆ DL_climate çš„é«˜æ–¯å“åº”æ›²çº¿ï¼‰"""

    def compute_transmission_factor(self, climate_df: pd.DataFrame) -> np.ndarray:
        temp = climate_df['temperature'].values
        precip = climate_df['precipitation'].values
        humidity = climate_df.get('humidity', pd.Series([75]*len(temp))).values

        # æ¸©åº¦å“åº”ï¼šé«˜æ–¯æ›²çº¿ï¼ˆ20-30Â°Cæœ€é€‚å®œï¼‰
        temp_factor = np.exp(-0.5 * ((temp - 25) / 5) ** 2)

        # é™æ°´å“åº”
        precip_factor = np.where(
            precip < 200,
            1 + 0.003 * precip,
            1 + 0.003 * 200 - 0.002 * (precip - 200)
        )
        precip_factor = np.clip(precip_factor, 0.5, 2.0)

        # æ¹¿åº¦å“åº”
        humidity_factor = np.where(humidity > 60, 0.5 + 0.01 * humidity, 0.8)

        return temp_factor * precip_factor * humidity_factor

    def get_optimal_climate_range(self) -> dict:
        return {
            'temperature': (20, 32),
            'precipitation': (50, 300),
            'humidity': (60, 90),
        }


class DengueFeatures(DiseaseFeatureEngineer):
    """ç™»é©çƒ­ç‰¹å¼‚æ€§ç‰¹å¾"""

    def compute_transmission_factor(self, climate_df: pd.DataFrame) -> np.ndarray:
        temp = climate_df['temperature'].values
        precip = climate_df['precipitation'].values

        # æ¸©åº¦å“åº”ï¼š28Â°C å³°å€¼
        temp_factor = np.exp(-0.5 * ((temp - 28) / 6) ** 2)

        # é™æ°´å“åº”
        precip_factor = 1 + 0.004 * np.minimum(precip, 250)

        return temp_factor * precip_factor

    def get_optimal_climate_range(self) -> dict:
        return {
            'temperature': (22, 34),
            'precipitation': (100, 400),
            'humidity': (65, 85),
        }


class CholeraFeatures(DiseaseFeatureEngineer):
    """éœä¹±ç‰¹å¼‚æ€§ç‰¹å¾"""

    def compute_transmission_factor(self, climate_df: pd.DataFrame) -> np.ndarray:
        temp = climate_df['temperature'].values
        precip = climate_df['precipitation'].values

        # æ¸©åº¦å“åº”
        temp_factor = np.where((temp >= 25) & (temp <= 35), 1.5, 0.8)

        # æ´ªæ°´äº‹ä»¶æ£€æµ‹
        precip_7d = climate_df['precipitation'].rolling(7, min_periods=1).sum().fillna(0).values
        flood_factor = np.where(precip_7d > np.percentile(precip_7d, 90), 2.0, 1.0)

        return temp_factor * flood_factor

    def get_optimal_climate_range(self) -> dict:
        return {
            'temperature': (15, 40),
            'precipitation': (0, 500),
            'humidity': (50, 95),
        }


class ZikaFeatures(DiseaseFeatureEngineer):
    """å¯¨å¡ç—…æ¯’ç‰¹å¾"""

    def compute_transmission_factor(self, climate_df: pd.DataFrame) -> np.ndarray:
        dengue_model = DengueFeatures()
        base_factor = dengue_model.compute_transmission_factor(climate_df)
        return base_factor * 0.7

    def get_optimal_climate_range(self) -> dict:
        return {
            'temperature': (22, 34),
            'precipitation': (100, 350),
            'humidity': (65, 85),
        }


class DomainFeatureManager:
    """ç®¡ç†æ‰€æœ‰ç–¾ç—…çš„ç‰¹å¾å·¥ç¨‹"""

    def __init__(self):
        se

# ============================================
# ç¬¬ 2 æ­¥ï¼šåˆ›å»ºå¢å¼ºç‰ˆ NLP æ£€æµ‹å™¨æ¨¡å— - Part 2
# ============================================
print("\n" + "="*70)
print("åˆ›å»ºå¢å¼ºç‰ˆ NLP æ£€æµ‹å™¨æ¨¡å—")
print("="*70)

# å®šä¹‰è¦å†™å…¥æ–‡ä»¶çš„ä»£ç å†…å®¹
nlp_enhanced_code = '''from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import numpy as np
import joblib

class EnhancedOutbreakDetector:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 3))
        self.outbreak_classifier = LogisticRegression(max_iter=2000, random_state=42)
        self.disease_classifier = LogisticRegression(max_iter=2000, random_state=42)
        self.disease_labels = ['malaria', 'dengue', 'cholera', 'zika']

    def train(self, texts: list, outbreak_labels: list, disease_labels: list):
        X = self.vectorizer.fit_transform(texts)

        # è®­ç»ƒçˆ†å‘åˆ†ç±»å™¨
        self.outbreak_classifier.fit(X, outbreak_labels)

        # è®­ç»ƒç–¾ç—…åˆ†ç±»å™¨
        outbreak_indices = [i for i, label in enumerate(outbreak_labels) if label == 1]
        if len(outbreak_indices) > 0:
            X_outbreak = X[outbreak_indices]
            y_disease = [disease_labels[i] for i in outbreak_indices]
            y_disease_encoded = [self.disease_labels.index(d) if d in self.disease_labels else 0
                                  for d in y_disease]
            self.disease_classifier.fit(X_outbreak, y_disease_encoded)

    def predict(self, texts: list) -> list:
        X = self.vectorizer.transform(texts)
        outbreak_pred = self.outbreak_classifier.predict(X)
        outbreak_proba = self.outbreak_classifier.predict_proba(X)[:, 1]

        results = []
        for i, text in enumerate(texts):
            disease = 'none'
            if outbreak_pred[i] == 1:
                disease_idx = self.disease_classifier.predict(X[i])[0]
                disease = self.disease_labels[int(disease_idx)]

            severity = 'high' if outbreak_proba[i] > 0.7 else 'medium' if outbreak_proba[i] > 0.4 else 'low'

            results.append({
                'text': text,
                'is_outbreak': bool(outbreak_pred[i]),
                'confidence': float(outbreak_proba[i]),
                'disease': disease,
                'severity': severity,
                'urgency_score': float(outbreak_proba[i])
            })
        return results

    def save(self, path: str):
        joblib.dump({
            'vectorizer': self.vectorizer,
            'outbreak_classifier': self.outbreak_classifier,
            'disease_classifier': self.disease_classifier,
            'disease_labels': self.disease_labels
        }, path)

    @classmethod
    def load(cls, path: str):
        data = joblib.load(path)
        instance = cls()
        instance.vectorizer = data['vectorizer']
        instance.outbreak_classifier = data['outbreak_classifier']
        instance.disease_classifier = data['disease_classifier']
        instance.disease_labels = data['disease_labels']
        return instance

def generate_expanded_training_set():
    malaria_outbreak = [
        'Malaria cases surge in rural districts following heavy monsoon rains',
        'WHO reports alarming increase in malaria infections across East Africa',
        'Emergency declared as malaria outbreak spreads rapidly',
        'Hospitals overwhelmed by malaria patients after flooding',
        'Record malaria deaths reported in past month',
        'Severe malaria cases strain health facilities',
        'Malaria epidemic declared after seasonal rains',
        'Anopheles mosquito population explodes creating risk',
        'Mass malaria treatment campaign launched',
        'Malaria transmission spikes with warm weather',
    ] * 2

    dengue_outbreak = [
        'Dengue fever outbreak grips capital as cases triple',
        'Aedes mosquito breeding explodes after urban flooding',
        'Hospitals run out of platelets amid dengue surge',
        'Cities declare dengue emergency with record infections',
        'Schools closed as dengue outbreak spreads',
        'Dengue death toll rises in monsoon regions',
        'Fumigation drive launched as dengue cases spike',
        'ICU beds full with severe dengue patients',
        'Dengue outbreak strains healthcare systems',
        'Climate patterns fuel worst dengue season',
    ] * 2

    cholera_outbreak = [
        'Cholera epidemic spreads through flood-devastated regions',
        'Water contamination triggers massive cholera outbreak',
        'Cholera cases surge after cyclone damages infrastructure',
        'Emergency rehydration stations set up for cholera',
        'Cholera deaths mount lacking clean water access',
        'Refugees face cholera crisis in overcrowded camps',
        'Vibrio cholerae detected in water sources after floods',
        'Cholera outbreak declared as diarrhea cases skyrocket',
        'International aid rushed to combat cholera epidemic',
        'Cholera transmission accelerates in coastal areas',
    ] * 2

    zika_outbreak = [
        'Zika virus cases rise as Aedes mosquitoes spread',
        'Pregnant women warned as Zika outbreak intensifies',
        'Zika-linked microcephaly cases reported in outbreak',
        'Travel warnings issued due to Zika outbreak',
        'Zika virus detected in previously disease-free areas',
        'Emergency Zika response teams deployed',
        'Zika outbreak prompts mosquito control efforts',
        'Birth defects rise as Zika outbreak continues',
        'International concern over expanding Zika outbreak',
        'Zika cases surge following warm winter season',
    ] * 2

    normal = [
        'New malaria vaccine shows promising trial results',
        'Community workers distribute insecticide-treated nets',
        'Annual malaria prevention campaign begins',
        'Research team discovers malaria prevention approach',
        'Government invests in malaria control infrastructure',
        'Routine malaria testing available at health centers',
        'Malaria awareness program educates villagers',
        'New diagnostic tool improves malaria detection',
        'Seasonal prevention measures rolled out',
        'Health ministry reports stable case numbers',
        'Farmers market opens with fresh produce',
        'New school construction completed in rural area',
        'Local team wins regional sports championship',
        'Cultural festival celebrates traditional arts',
        'Road improvement project enhances connectivity',
    ] * 3

    all_texts = malaria_outbreak + dengue_outbreak + cholera_outbreak + zika_outbreak + normal
    outbreak_labels = [1] * (len(malaria_outbreak) + len(dengue_outbreak) +
                             len(cholera_outbreak) + len(zika_outbreak)) + [0] * len(normal)
    disease_labels = (['malaria'] * len(malaria_outbreak) +
                     ['dengue'] * len(dengue_outbreak) +
                     ['cholera'] * len(cholera_outbreak) +
                     ['zika'] * len(zika_outbreak) +
                     ['none'] * len(normal))

    return all_texts, outbreak_labels, disease_labels
'''

# ç¡®ä¿ç›®å½•å­˜åœ¨
import os
os.makedirs('models', exist_ok=True)

# å†™å…¥æ–‡ä»¶
with open('models/nlp_detector_enhanced.py', 'w', encoding='utf-8') as f:
    f.write(nlp_enhanced_code)

print("âœ… models/nlp_detector_enhanced.py å·²åˆ›å»º")
print("\nâœ… æ‰€æœ‰èåˆæ¨¡å—æ–‡ä»¶åˆ›å»ºå®Œæˆ")

# ============================================
# ç¬¬ 3 æ­¥ï¼šè·å–çœŸå®æ•°æ®
# ============================================
print("\n" + "="*70)
print("  ğŸŒ è·å–çœŸå®æ•°æ®ï¼ˆNASA/WHO/GDELTï¼‰")
print("="*70)

import pandas as pd
import os

# é¦–å…ˆæ£€æŸ¥å½“å‰ç›®å½•
print(f"\nå½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"\nç›®å½•ç»“æ„:")
!ls -la

# æ£€æŸ¥ data æ–‡ä»¶å¤¹
if os.path.exists('data'):
    print(f"\ndata/ æ–‡ä»¶å¤¹å†…å®¹:")
    !ls -la data/
else:
    print("\nâš ï¸  data/ æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸­...")
    !mkdir -p data

# æ£€æŸ¥ fetch_real_data.py æ˜¯å¦å­˜åœ¨
fetch_script_path = 'data/fetch_real_data.py'
if os.path.exists(fetch_script_path):
    print(f"\nâœ… æ‰¾åˆ° {fetch_script_path}")
    print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(fetch_script_path)} å­—èŠ‚")

    # è¿è¡Œæ•°æ®è·å–è„šæœ¬
    print("\nå¼€å§‹è¿è¡Œæ•°æ®è·å–è„šæœ¬...")
    !python data/fetch_real_data.py

elif os.path.exists('fetch_real_data.py'):
    print(f"\nâœ… æ‰¾åˆ° fetch_real_data.pyï¼ˆåœ¨å½“å‰ç›®å½•ï¼‰")
    !python fetch_real_data.py

else:
    print(f"\nâš ï¸  æœªæ‰¾åˆ° fetch_real_data.py")
    print("å°è¯•ç›´æ¥åœ¨ Python ä¸­å¯¼å…¥...")

    # æ–¹æ¡ˆ Bï¼šç›´æ¥å¯¼å…¥å¹¶è¿è¡Œ
    try:
        import sys
        sys.path.insert(0, 'data')
        import fetch_real_data
        print("âœ… æˆåŠŸå¯¼å…¥ fetch_real_data æ¨¡å—")

        # å¦‚æœæ¨¡å—æœ‰ main å‡½æ•°ï¼Œè°ƒç”¨å®ƒ
        if hasattr(fetch_real_data, 'main'):
            fetch_real_data.main()
        elif hasattr(fetch_real_data, 'fetch_all_data'):
            fetch_real_data.fetch_all_data()
        else:
            print("âš ï¸  æ¨¡å—æ²¡æœ‰ main() æˆ– fetch_all_data() å‡½æ•°")
            print("å¯ç”¨çš„å‡½æ•°:", dir(fetch_real_data))

    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        print("\nå°†ä½¿ç”¨åˆæˆæ•°æ®ä½œä¸ºåå¤‡æ–¹æ¡ˆ...")

# æ£€æŸ¥æ•°æ®æ˜¯å¦ç”Ÿæˆ
print("\n" + "="*70)
print("æ£€æŸ¥æ•°æ®æ–‡ä»¶")
print("="*70)

data_files = [
    'data/real_data.csv',
    'real_data.csv',
    'data/climate_data.csv',
    'data/disease_data.csv'
]

df = None
for data_file in data_files:
    if os.path.exists(data_file):
        print(f"\nâœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_file}")
        try:
            df = pd.read_csv(data_file)
            print(f"   æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            print(f"   åˆ—å: {df.columns.tolist()}")
            print(f"\næ•°æ®é¢„è§ˆ:")
            print(df.head())
            break
        except Exception as e:
            print(f"   âŒ åŠ è½½å¤±è´¥: {e}")

if df is None:
    print("\nâš ï¸  æœªæ‰¾åˆ°çœŸå®æ•°æ®æ–‡ä»¶")
    print("ç”Ÿæˆåˆæˆæ•°æ®ä½œä¸ºåå¤‡...")

    # ç”Ÿæˆç®€å•çš„åˆæˆæ•°æ®
    import numpy as np
    from datetime import datetime, timedelta

    n_samples = 1000
    start_date = datetime(2020, 1, 1)

    dates = [start_date + timedelta(days=i) for i in range(n_samples)]
    diseases = np.random.choice(['malaria', 'dengue', 'cholera', 'zika'], n_samples)

    df = pd.DataFrame({
        'date': dates,
        'disease': diseases,
        'temperature': np.random.normal(27, 5, n_samples),
        'precipitation': np.random.gamma(2, 50, n_samples),
        'humidity': np.random.normal(75, 10, n_samples),
        'cases': np.random.poisson(100, n_samples),
        'outbreak': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])
    })

    df.to_csv('data/real_data.csv', index=False)
    print(f"\nâœ… åˆæˆæ•°æ®å·²ç”Ÿæˆ: {len(df)} è¡Œ")
    print(f"   ä¿å­˜ä½ç½®: data/real_data.csv")
    print(f"\næ•°æ®é¢„è§ˆ:")
    print(df.head())

print("\nâœ… æ•°æ®å‡†å¤‡å®Œæˆ")

# ============================================
# ç¬¬ 4 æ­¥ï¼šæ•°æ®é¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹
# ============================================
print("\n" + "="*70)
print("  ğŸ”§ æ•°æ®é¢„å¤„ç†ä¸é¢†åŸŸç‰¹å¾å·¥ç¨‹")
print("="*70)

# å¯¼å…¥æ–°åˆ›å»ºçš„æ¨¡å—
import sys
sys.path.insert(0, 'models')
from disease_domain_features import DomainFeatureManager

# åˆå§‹åŒ–ç‰¹å¾ç®¡ç†å™¨
feature_manager = DomainFeatureManager()

# ä¸ºæ¯ç§ç–¾ç—…åº”ç”¨ç‰¹å¾å·¥ç¨‹
if df is not None and 'disease' in df.columns:
    diseases = df['disease'].unique()
    print(f"\næ£€æµ‹åˆ°ç–¾ç—…ç±»å‹: {diseases}")

    enhanced_dfs = []
    for disease in diseases:
        if disease in ['malaria', 'dengue', 'cholera', 'zika']:
            print(f"\nå¤„ç† {disease} æ•°æ®...")
            disease_df = df[df['disease'] == disease].copy()

            # åº”ç”¨é¢†åŸŸç‰¹å¾å·¥ç¨‹
            climate_cols = ['temperature', 'precipitation']
            if 'humidity' in disease_df.columns:
                climate_cols.append('humidity')

            climate_df = disease_df[climate_cols].copy()
            enhanced = feature_manager.engineer_features(climate_df, disease)

            # åˆå¹¶å›åŸæ•°æ®
            for col in enhanced.columns:
                if col not in disease_df.columns:
                    disease_df[col] = enhanced[col].values

            enhanced_dfs.append(disease_df)
            print(f"  âœ… {disease} ç‰¹å¾å¢å¼ºå®Œæˆï¼Œæ–°å¢ {len(enhanced.columns) - len(climate_cols)} ä¸ªç‰¹å¾")

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    df_enhanced = pd.concat(enhanced_dfs, ignore_index=True)
    df_enhanced.to_csv('data/enhanced_data.csv', index=False)
    print(f"\nâœ… å¢å¼ºæ•°æ®å·²ä¿å­˜: data/enhanced_data.csv")
else:
    print("\nâš ï¸  è·³è¿‡ç‰¹å¾å·¥ç¨‹ï¼ˆæ•°æ®æ ¼å¼é—®é¢˜ï¼‰")
    df_enhanced = df

# ============================================
# ç¬¬ 5 æ­¥ï¼šè®­ç»ƒå¢å¼ºç‰ˆç–¾ç—…é¢„æµ‹æ¨¡å‹
# ============================================
print("\n" + "="*70)
print("  ğŸ¤– è®­ç»ƒç–¾ç—…ç‰¹å¼‚æ€§é¢„æµ‹æ¨¡å‹")
print("="*70)

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import joblib

class EnhancedDiseasePredictor:
    def __init__(self, disease: str):
        self.disease = disease
        self.rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
        self.gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)
        self.lr_model = LogisticRegression(max_iter=1000, random_state=42)
        self.weights = {'rf': 0.45, 'gb': 0.45, 'lr': 0.10}
        self.feature_names = None

    def train(self, X, y):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

        print(f"  è®­ç»ƒ {self.disease} æ¨¡å‹...")
        self.rf_model.fit(X_train, y_train)
        self.gb_model.fit(X_train, y_train)
        self.lr_model.fit(X_train, y_train)

        # è¯„ä¼°
        y_pred, y_pred_proba = self.predict(X_test)
        print(f"\n  {self.disease.upper()} æ€§èƒ½:")
        print(classification_report(y_test, y_pred, target_names=['æ­£å¸¸', 'çˆ†å‘']))
        print(f"  ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}")

    def predict(self, X):
        rf_pred = self.rf_model.predict_proba(X)[:, 1]
        gb_pred = self.gb_model.predict_proba(X)[:, 1]
        lr_pred = self.lr_model.predict_proba(X)[:, 1]
        ensemble_pred = self.weights['rf'] * rf_pred + self.weights['gb'] * gb_pred + self.weights['lr'] * lr_pred
        return (ensemble_pred > 0.5).astype(int), ensemble_pred

    def save(self, path: str):
        joblib.dump({
            'disease': self.disease,
            'rf_model': self.rf_model,
            'gb_model': self.gb_model,
            'lr_model': self.lr_model,
            'weights': self.weights,
            'feature_names': self.feature_names
        }, path)

    @classmethod
    def load(cls, path: str):
        data = joblib.load(path)
        instance = cls(data['disease'])
        instance.rf_model = data['rf_model']
        instance.gb_model = data['gb_model']
        instance.lr_model = data['lr_model']
        instance.weights = data['weights']
        instance.feature_names = data['feature_names']
        return instance

# è®­ç»ƒæ‰€æœ‰ç–¾ç—…æ¨¡å‹
if df_enhanced is not None and 'outbreak' in df_enhanced.columns:
    for disease in ['malaria', 'dengue', 'cholera', 'zika']:
        disease_data = df_enhanced[df_enhanced['disease'] == disease]

        if len(disease_data) < 50:
            print(f"\nâš ï¸  {disease} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue

        print(f"\n{'='*60}")
        print(f"è®­ç»ƒ {disease.upper()} æ¨¡å‹")
        print('='*60)

        # âœ… åªé€‰æ‹©åŸºç¡€ç‰¹å¾ + å½“å‰ç–¾ç—…çš„ç‰¹å¾
        feature_cols = ['temperature', 'precipitation', 'humidity']
        disease_specific_cols = [col for col in disease_data.columns
                                if col.startswith(f'{disease}_')]
        feature_cols.extend(disease_specific_cols)

        # æ‰“å°ç‰¹å¾ä¿¡æ¯
        print(f"  åŸºç¡€ç‰¹å¾: {feature_cols[:3]}")
        print(f"  {disease} ç‰¹å®šç‰¹å¾: {disease_specific_cols}")
        print(f"  æ€»ç‰¹å¾æ•°: {len(feature_cols)}")

        X = disease_data[feature_cols].fillna(0).values
        y = disease_data['outbreak'].values

        # è®­ç»ƒ
        model = EnhancedDiseasePredictor(disease)
        model.feature_names = feature_cols  # åªä¿å­˜ 7 ä¸ªç‰¹å¾ï¼ˆ3åŸºç¡€ + 4ç–¾ç—…ç‰¹å®šï¼‰
        model.train(X, y)

        # ä¿å­˜
        model.save(f'saved_models/{disease}_predictor_enhanced.pkl')
        print(f"\nâœ… {disease} æ¨¡å‹å·²ä¿å­˜")
        print(f"   æ¨¡å‹ç‰¹å¾æ•°: {len(model.feature_names)}")
else:
    print("\nâš ï¸  è·³è¿‡ç–¾ç—…æ¨¡å‹è®­ç»ƒï¼ˆæ•°æ®ä¸å¯ç”¨ï¼‰")

# ============================================
# ç¬¬ 6 æ­¥ï¼šè®­ç»ƒå¢å¼ºç‰ˆ NLP æ£€æµ‹å™¨
# ============================================
print("\n" + "="*70)
print("  ğŸ“° è®­ç»ƒå¢å¼ºç‰ˆ NLP çˆ†å‘æ£€æµ‹å™¨")
print("="*70)

from nlp_detector_enhanced import EnhancedOutbreakDetector, generate_expanded_training_set

# ç”Ÿæˆè®­ç»ƒé›†
texts, outbreak_labels, disease_labels = generate_expanded_training_set()
print(f"\nNLP è®­ç»ƒé›†: {len(texts)} æ ·æœ¬")
print(f"  çˆ†å‘æ ·æœ¬: {sum(outbreak_labels)}")
print(f"  æ­£å¸¸æ ·æœ¬: {len(texts) - sum(outbreak_labels)}")

# è®­ç»ƒ
nlp_model = EnhancedOutbreakDetector()
nlp_model.train(texts, outbreak_labels, disease_labels)
nlp_model.save('saved_models/nlp_detector_enhanced.pkl')

print("\nâœ… NLP æ¨¡å‹è®­ç»ƒå®Œæˆ")

# æµ‹è¯•
test_headlines = [
    'Massive dengue outbreak in Southeast Asia after floods',
    'Malaria cases surge 40% in East Africa highlands',
    'Cholera spreads through flood-damaged water systems',
    'Local farmers celebrate successful harvest season',
    'Zika emergency declared in Caribbean islands',
]

print("\n" + "="*70)
print("NLP æ£€æµ‹æµ‹è¯•")
print("="*70)
results = nlp_model.predict(test_headlines)
for r in results:
    emoji = 'ğŸ”´ OUTBREAK' if r['is_outbreak'] else 'ğŸŸ¢ Normal'
    print(f"{emoji} | {r['disease']:8s} | conf={r['confidence']:.2f} | {r['severity']}")
    print(f"   \"{r['text'][:60]}...\"\n")

# ============================================
# ç¬¬ 7 æ­¥ï¼šè®­ç»ƒæ°”å€™é¢„æµ‹å™¨
# ============================================
print("\n" + "="*70)
print("  ğŸŒ¡ è®­ç»ƒæ°”å€™é¢„æµ‹å™¨")
print("="*70)

# å¦‚æœæœ‰ train_real.pyï¼Œè¿è¡Œå®ƒæ¥è®­ç»ƒæ°”å€™æ¨¡å‹
import os
if os.path.exists('train_real.py'):
    print("ä½¿ç”¨ train_real.py è®­ç»ƒæ°”å€™æ¨¡å‹...")
    !python train_real.py
else:
    print()
    !python train.py

print("\nâœ… æ°”å€™é¢„æµ‹å™¨è®­ç»ƒå®Œæˆ")

# ============================================
# ç¬¬ 8 æ­¥ï¼šåˆ›å»ºèåˆé›†æˆå¼•æ“
# ============================================
print("\n" + "="*70)
print("  ğŸ¯ åˆ›å»ºèåˆé£é™©è¯„ä¼°å¼•æ“")
print("="*70)

import numpy as np

class FusionRiskEngine:
    """èåˆé£é™©è¯„ä¼°å¼•æ“"""

    def __init__(self, disease_model, nlp_model):
        self.disease_model = disease_model
        self.nlp_model = nlp_model
        self.base_weights = {'climate': 0.35, 'disease': 0.50, 'nlp': 0.15}

    def assess_risk(self, climate_df, news_texts, disease='malaria'):
        # âœ… ä¿®æ”¹ï¼šç¡®ä¿ climate_df å·²ç»æ˜¯å¢å¼ºåçš„ç‰¹å¾
        # å¦‚æœä¼ å…¥çš„æ˜¯åŸå§‹æ•°æ®ï¼Œå…ˆè¿›è¡Œç‰¹å¾å·¥ç¨‹
        if 'transmission_factor' not in climate_df.columns:
            from disease_domain_features import DomainFeatureManager
            manager = DomainFeatureManager()
            enhanced = manager.engineer_features(climate_df, disease)
        else:
            enhanced = climate_df

        # 2. ç–¾ç—…æ¨¡å‹é¢„æµ‹
        # âœ… ä½¿ç”¨æ¨¡å‹ä¿å­˜çš„ç‰¹å¾åˆ—è¡¨
        if hasattr(self.disease_model, 'feature_names'):
            feature_cols = self.disease_model.feature_names
        else:
            feature_cols = [col for col in enhanced.columns
                           if not col.startswith('date')]

        X = enhanced[feature_cols].fillna(0).values[-1:]  # æœ€æ–°ä¸€è¡Œ
        _, disease_prob = self.disease_model.predict(X)
        disease_risk = disease_prob[0] * 100

        # 3. NLP åˆ†æ
        nlp_results = self.nlp_model.predict(news_texts)
        relevant = [r for r in nlp_results if r['is_outbreak'] and r['disease'] == disease]
        nlp_risk = np.mean([r['confidence'] for r in relevant]) * 100 if relevant else 0

        # 4. æ°”å€™é£é™©ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        temp = enhanced['temperature'].iloc[-1] if 'temperature' in enhanced.columns else climate_df['temperature'].iloc[-1]
        precip = enhanced['precipitation'].iloc[-1] if 'precipitation' in enhanced.columns else climate_df['precipitation'].iloc[-1]

        from disease_domain_features import DomainFeatureManager
        manager = DomainFeatureManager()
        optimal = manager.disease_models[disease].get_optimal_climate_range()

        temp_in_range = optimal['temperature'][0] <= temp <= optimal['temperature'][1]
        precip_in_range = optimal['precipitation'][0] <= precip <= optimal['precipitation'][1]
        climate_risk = 75 if (temp_in_range and precip_in_range) else 40

        # 5. åŠ æƒè®¡ç®—
        final_score = (
            self.base_weights['climate'] * climate_risk +
            self.base_weights['disease'] * disease_risk +
            self.base_weights['nlp'] * nlp_risk
        )

        risk_level = 'critical' if final_score >= 75 else \
                    'high' if final_score >= 60 else \
                    'medium' if final_score >= 40 else 'low'

        return {
            'risk_score': round(final_score, 1),
            'risk_level': risk_level,
            'outbreak_probability': round(disease_prob[0], 3),
            'component_scores': {
                'climate_risk': round(climate_risk, 1),
                'disease_risk': round(disease_risk, 1),
                'nlp_risk': round(nlp_risk, 1)
            },
            'nlp_signals': nlp_results
        }

# ============================================
# ç¬¬ 9 æ­¥ï¼šç«¯åˆ°ç«¯æµ‹è¯•
# ============================================
print("\n" + "="*70)
print("  ğŸ§ª ç«¯åˆ°ç«¯æµ‹è¯•")
print("="*70)

import pandas as pd

# åŠ è½½æ¨¡å‹
try:
    malaria_model = EnhancedDiseasePredictor.load('saved_models/malaria_predictor_enhanced.pkl')
    nlp_model = EnhancedOutbreakDetector.load('saved_models/nlp_detector_enhanced.pkl')

    # åˆ›å»ºå¼•æ“
    engine = FusionRiskEngine(malaria_model, nlp_model)

    # æµ‹è¯•æ•°æ®
    test_climate = pd.DataFrame({
        'temperature': [26, 27, 28, 27, 26, 25, 24, 25, 26, 27],
        'precipitation': [120, 150, 180, 200, 180, 160, 140, 130, 150, 170],
        'humidity': [75, 78, 80, 82, 80, 78, 76, 77, 79, 81],
    })

    # âœ… å…³é”®ä¿®æ”¹ï¼šåº”ç”¨é¢†åŸŸç‰¹å¾å·¥ç¨‹
    from disease_domain_features import DomainFeatureManager
    feature_manager = DomainFeatureManager()
    test_climate_enhanced = feature_manager.engineer_features(test_climate, 'malaria')

    print(f"\nâœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ:")
    print(f"   åŸå§‹ç‰¹å¾: {test_climate.shape[1]} ä¸ª")
    print(f"   å¢å¼ºç‰¹å¾: {test_climate_enhanced.shape[1]} ä¸ª")
    print(f"   ç‰¹å¾åˆ—è¡¨: {test_climate_enhanced.columns.tolist()}")

    test_news = [
        'Malaria outbreak spreads in rural areas after heavy rains',
        'WHO reports increased malaria transmission in East Africa',
        'Emergency malaria response teams deployed',
    ]

    # è¯„ä¼° - ä½¿ç”¨å¢å¼ºåçš„æ•°æ®
    result = engine.assess_risk(test_climate_enhanced, test_news, disease='malaria')

    # æ‰“å°ç»“æœ
    print("\n" + "="*70)
    print("  èåˆé£é™©è¯„ä¼°ç»“æœ - MALARIA")
    print("="*70)
    print(f"  é£é™©åˆ†æ•°:      {result['risk_score']}/100")
    print(f"  é£é™©ç­‰çº§:      {result['risk_level'].upper()}")
    print(f"  çˆ†å‘æ¦‚ç‡:      {result['outbreak_probability']*100:.1f}%")
    print(f"\n  ç»„ä»¶åˆ†æ•°:")
    for comp, score in result['component_scores'].items():
        print(f"    {comp:20s} {score:>6.1f}/100")
    print("="*70)

    print("\nâœ… ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸï¼")

except Exception as e:
    print(f"\nâš ï¸  æµ‹è¯•å¤±è´¥: {str(e)}")
    print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    import traceback
    traceback.print_exc()

    # æ£€æŸ¥æ¨¡å‹çš„ç‰¹å¾è¦æ±‚
    if 'malaria_model' in locals():
        print(f"\næ¨¡å‹æœŸæœ›çš„ç‰¹å¾æ•°é‡: {len(malaria_model.feature_names)}")
        print(f"æ¨¡å‹æœŸæœ›çš„ç‰¹å¾åç§°: {malaria_model.feature_names}")

